{
  
    
        "post0": {
            "title": "Steganography for Text - Hiding Text in Images",
            "content": "Photo by Daniel Gregoire on Usplash . What is Steganography . Steganography is the practice of concealing a file, message, image, or video within another file, message, image, or video. Inspired by this excellent blog post by Kelvin Salton do Prado explaining a simple approach for concealing one image within another image, I have created this short application to hide a text message inside a given image, without causing any noticeable change to the original image. . I have also added a nice visualization at the end capturing the whole process. . Note: This application requires an image with 3 channels (e.g. RGB) hence grayscale images will not work . The core idea behind this implementation is actually quite simple and the key aspects are as follows: . Each pixel of an RGB image consists of three 8-bit values corresponding to the three channels | Each of these three 8-bit values consist of 4 most-significant-bits (MSB) and 4 least-significant-bits (LSB) | Hence every pixel is a combination of 12 (4+4+4) MSBs and 12 (4+4+4) LSBs | As the name suggests, the 12 LSBs are less relevant and can be modified without any noticeable change in the image | . Following are the steps involved in the hide operation: . Read the input image into a 3D array of pixels of size HxWxC (H=height, W=width, C=channels=3 for RGB) | Read the input text file and store contents into an array of bytes | Convert every byte(character) of the text into a 12-bit binary format | Starting with the first pixel (n=0) of the image matrix, replace the 12 LSBs of pixel-n with the 12-bit value of the byte-n from the text byte-array | Repeat above operation (n=n+1 every time) until there are no more bytes left in the text byte-array | In the last iteration, replace the 12 LSBs of pixel-n with a special 12-bit end-of-text indicator value | Save the modified image matrix into a new image file | . The following image should help illustrate the above steps using an example . . Similarly, the steps involved in the unhide operation are as follows: . Read the input image into a 3D array of pixels of size HxWxC (H=height, W=width, C=channels=3 for RGB) | Starting with the first pixel (n=0) of the image matrix, read the 12 LSBs of pixel-n and add it to a byte array | Repeat above operation (n=n+1 every time) until you find the end-of-text indicator value in the 12 LSBs of pixel-n | Decode the byte array and save the contents into a new text file | . We start with importing the libraries we need and setting the plot mode for inline display . import base64 import cv2 import time import imutils import os import numpy as np import matplotlib.pyplot as plt from IPython.display import display from IPython.display import Video %matplotlib inline . In this script we will be using some static configuration parameters, which we wouldn&#39;t normally require to change. . A special note for the parameter eotIn which is a special signature used to indicate the end of text. . This allows the extraction logic to stop processing the image when all the text has been extracted, hence saving time. . # define configuration params figureSize = (12,10) # image size for display displayWidth = (1024+128) # max width of image for display maxDebugBytes = 10 # max num of bytes to view in debug mode eotInd = 2730 # &#39;101010101010&#39; - 12 bit End-Of-Text indicator maxCharRange = 127 # max range of characters as per ASCII table debugMode = False # flag to view debug prints visHoldTime = 1 # time in milisec to hold visualization per character visFps = 30 # frames per second for the captured visualization video visStack = 0 # direction (0-horizontal/1-vertical) for visualization stack . Then we move on to define the core logic of our script, the Steganography class and it&#39;s member functions. . This class implements the hide and unhide operations along with some utility functions. . class Steganography(object): @staticmethod def __int_to_bin(rgb): &quot;&quot;&quot;Convert an integer tuple to a binary (string) tuple. :param rgb: An integer tuple (e.g. (220, 110, 96)) :return: A string tuple (e.g. (&quot;00101010&quot;, &quot;11101011&quot;, &quot;00010110&quot;)) &quot;&quot;&quot; r, g, b = rgb return (&#39;{0:08b}&#39;.format(r), &#39;{0:08b}&#39;.format(g), &#39;{0:08b}&#39;.format(b)) @staticmethod def __bin_to_int(rgb): &quot;&quot;&quot;Convert a binary (string) tuple to an integer tuple. :param rgb: A string tuple (e.g. (&quot;00101010&quot;, &quot;11101011&quot;, &quot;00010110&quot;)) :return: Return an int tuple (e.g. (220, 110, 96)) &quot;&quot;&quot; r, g, b = rgb return (int(r, 2), int(g, 2), int(b, 2)) @staticmethod def __hide_rgb(rgb1, rgb2): &quot;&quot;&quot;hide two RGB tuples. :param rgb1: A string tuple (e.g. (&quot;00101010&quot;, &quot;11101011&quot;, &quot;00010110&quot;)) :param rgb2: Another string tuple (e.g. (&quot;00101010&quot;, &quot;11101011&quot;, &quot;00010110&quot;)) :return: An integer tuple with the two RGB values hidden. &quot;&quot;&quot; r1, g1, b1 = rgb1 r2, g2, b2 = rgb2 rgb = (r1[:4] + r2[:4], g1[:4] + g2[:4], b1[:4] + b2[:4]) return rgb @staticmethod def hide(img, text, debug=False): &quot;&quot;&quot;hide an image content with a text. :param img: Image file :param text: Text file :param debug: Flag for debug prints :return: A new hidden image. &quot;&quot;&quot; # check is image path is valid if not os.path.exists(img): print(&quot;!! Unable to locate image file:&quot;,img) return False,None # check is text path is valid if not os.path.exists(text): print(&quot;!! Unable to locate text file:&quot;,text) return False,None # Load the image image = cv2.imread(img,cv2.IMREAD_UNCHANGED) image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) # Clone the original image to create a copy that will contain hidden content new_image = image.copy() # check if image contains 3 channels, else quit im_shape = image.shape if len(im_shape) != 3: print(&quot;!! Unable to hide text as image does not have 3 channels !!&quot;) return False,new_image elif im_shape[2] != 3: print(&quot;!! Unable to hide text as image does not have 3 channels !!&quot;) return False,new_image # Open the text file and read the content fp = open(text, &#39;rb&#39;) text_bin = fp.read() fp.close() print(&quot;Length of text: {} chars&quot;.format(len(text_bin))) # check if image size is sufficient to encode full text, else quit required_bytes = len(text_bin) * 3 if required_bytes &gt; im_shape[0] * im_shape[1] * 3: print(&quot;!! Unable to hide full text as image does not have sufficient size !!&quot;) return False,new_image # initialize variables idx = 0 break_flag = False for i in range(im_shape[0]): for j in range(im_shape[1]): rgb1 = Steganography.__int_to_bin(image[i,j]) if idx == len(text_bin): # if no more text left to hide, insert the end of text signature bin_val = &quot;{0:012b}&quot;.format(eotInd) break_flag = True if debug: print(&quot;Hit end of text at idx:&quot;,idx) print(&quot;No of bytes used:&quot;, idx*3) else: if text_bin[idx] &gt; maxCharRange: # if character is out of max range, insert a &#39;dot&#39; character in 12-bit binary format bin_val = &quot;{0:012b}&quot;.format(ord(&#39;.&#39;)) else: # convert character to 12-bit binary format bin_val = &quot;{0:012b}&quot;.format(text_bin[idx]) # split into 3 channels of 4 bits each rgb2 = (bin_val[:4],bin_val[4:8],bin_val[8:12]) # hide the two pixels and convert it to a integer tuple rgb = Steganography.__hide_rgb(rgb1, rgb2) new_image[i,j] = Steganography.__bin_to_int(rgb) if debug: if idx &lt; maxDebugBytes: # visualize first maxDebugBytes # print(text_bin[idx]) # print(chr(text_bin[idx])) print(&quot;bin_val[{}]:{}&quot;.format(idx,bin_val)) idx += 1 if break_flag == True: break if break_flag == True: break plt.figure(figsize=figureSize) plt.imshow(imutils.resize(image,width=displayWidth)) plt.title(&#39;Input Image&#39;) plt.xticks([]), plt.yticks([]) # Hides the graph ticks and x / y axis plt.show() plt.figure(figsize=figureSize) plt.imshow(imutils.resize(new_image,width=displayWidth)) plt.title(&#39;Hidden Image&#39;) plt.xticks([]), plt.yticks([]) # Hides the graph ticks and x / y axis plt.show() return True,new_image @staticmethod def unhide(img,visualize,videofile,debug=False): &quot;&quot;&quot;Unhide an image. :param img: The input image. :param debug: Flag for debug prints :return: The unhidden/extracted text. &quot;&quot;&quot; # check is image path is valid if not os.path.exists(img): print(&quot;!! Unable to locate image file:&quot;,img) return False,None # Load the image image = cv2.imread(img,cv2.IMREAD_UNCHANGED) image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) # Store the image size im_shape = image.shape # check if image contains 3 channels, else quit if len(im_shape) != 3: print(&quot;!! Unable to extract text as image does not have 3 channels !!&quot;) return False,None elif im_shape[2] != 3: print(&quot;!! Unable to extract text as image does not have 3 channels !!&quot;) return False,None # initialize variables text_bin = [] idx = 0 break_flag = False # create a canvas for displaying extracted text text_canvas = np.zeros_like(image) # create a white canvas for displaying image white_canvas = 255 * np.ones_like(image) video_out = None if visualize.lower() == &#39;true&#39;: # Define the codec and create VideoWriter object #fourcc = cv2.VideoWriter_fourcc(*&#39;MP4V&#39;) #fourcc = cv2.VideoWriter_fourcc(*&#39;X264&#39;) fourcc = cv2.VideoWriter_fourcc(*&#39;avc1&#39;) # fourcc = cv2.VideoWriter_fourcc(*&#39;XVID&#39;) video_width = displayWidth video_height = int(0.5*displayWidth*im_shape[0]/im_shape[1]) # Open the video file # video_out = cv2.VideoWriter(videofile,fourcc,visFps, (im_shape[1],im_shape[0])) video_out = cv2.VideoWriter(videofile,fourcc,visFps, (video_width,video_height)) print(&quot;Begin processing image file&quot;) for i in range(im_shape[0]): for j in range(im_shape[1]): # Get the RGB (as a string tuple) from the current pixel r, g, b = Steganography.__int_to_bin(image[i,j]) # Extract the last 4 bits (corresponding to the hidden text) bin_val = r[4:] + g[4:] + b[4:] if debug: # view first maxDebugBytes bytes if idx &lt; maxDebugBytes: print(&quot;bin_val[{}]:{}&quot;.format(idx,bin_val)) # Convert it to an integer int_val = int(bin_val,2) if int_val == eotInd: # Check if End-Of-Text indicator is found if debug: print(&quot;Found end of text signature at index:&quot;, idx) break_flag = True elif int_val &lt;= maxCharRange: # only take characters within max range and append to output list text_bin.append(int_val) if visualize.lower() == &#39;true&#39;: # visualize the extraction process try: xpos = (j*30) % im_shape[1] ypos = i+30 + (j*30//im_shape[1]) * 30 cv2.putText(text_canvas, chr(text_bin[idx]), (xpos,ypos),cv2.FONT_HERSHEY_SIMPLEX,1.0,(0, 255, 0),4) # create a canvas for displaying original image while extraction with some blurring effect img_canvas = image.copy() img_canvas = cv2.addWeighted(img_canvas, 0.30, white_canvas, 0.70, 0) # show a small moving box to indicate pixel processing rectx = (j*30) % im_shape[1] recty = (i + (j*30//im_shape[1]) * 30) % im_shape[0] rectw = 30 recth = 30 cv2.rectangle(img_canvas, (rectx, recty), (rectx+rectw, recty+recth), (0,0,255), 5) if idx%20 &lt; 10: # Add a blinking text effect cv2.putText(img_canvas, &#39;Scanning Image&#39;, (int(0.6* im_shape[1]//2),im_shape[0]//2),cv2.FONT_HERSHEY_SIMPLEX,3.0,(255, 0, 0), 10) if visStack == 0: # stack_img = np.hstack((img_canvas,text_canvas)) stack_img = np.hstack((imutils.resize(img_canvas,width=displayWidth//2),imutils.resize(text_canvas,width=displayWidth//2))) else: # stack_img = np.vstack((img_canvas,text_canvas)) stack_img = np.vstack((imutils.resize(img_canvas,width=displayWidth//2),imutils.resize(text_canvas,width=displayWidth//2))) stack_img = cv2.cvtColor(stack_img, cv2.COLOR_RGB2BGR) video_out.write(cv2.resize(stack_img,(video_width,video_height))) except Exception as err: print(&quot;!! Visualization error:&quot;, err) visualize = &#39;false&#39; idx += 1 if break_flag == True: break if break_flag == True: break print(&quot;Finished processing image file&quot;) if debug: # view first maxDebugBytes print(&quot;view first {} bytes&quot;.format(maxDebugBytes)) print(text_bin[:maxDebugBytes]) print(bytes(text_bin[:maxDebugBytes])) print(&quot;maxval:&quot;,max(text_bin)) print(&quot;minval:&quot;,min(text_bin)) if video_out != None: # Close the video file video_out.release() plt.figure(figsize=figureSize) plt.imshow(imutils.resize(image,width=displayWidth)) plt.title(&#39;Original Image&#39;) plt.xticks([]), plt.yticks([]) # Hides the graph ticks and x / y axis plt.show() try: plt.figure(figsize=figureSize) plt.imshow(imutils.resize(text_canvas,width=displayWidth)) plt.title(&#39;Unhidden Text&#39;) plt.xticks([]), plt.yticks([]) # Hides the graph ticks and x / y axis plt.show() text_data = bytes(text_bin).decode() print(&quot;Unhidden Text:&quot;) print(&quot;===================================&quot;) print(text_data) print(&quot;===================================&quot;) except Exception as err: print(&quot;!! Decode Error:&quot;,err) return True,bytes(text_bin) . With the core logic defined, we will now define a simple driver function to invoke the hide operation. . This function accepts the required inputs, calls the hide function and saves the output image . def hide(img, text, output): start_time = time.time() ret_val,hidden_image = Steganography.hide(img,text,debugMode) end_time = time.time() if not ret_val: print(&quot;!! hide Failure !!&quot;) return print(&quot;Total time taken for hide: {:0.02f}s&quot;.format(end_time-start_time)) hidden_image = cv2.cvtColor(hidden_image, cv2.COLOR_RGB2BGR) cv2.imwrite(output,hidden_image) . We will configure the input parameters for the hide operation, providing the names of the input image and text files along with the output image file. . I have configured them as per some sample files which are included as part of this demonstration. . You can change these values as per your choice of image and text content. . img = &#39;../images/img1.jpg&#39; text = &#39;../images/text1.txt&#39; output = &#39;../images/output.png&#39; . We are now ready to perform the hide operation . hide(img,text,output) . Length of text: 1444 chars . Total time taken for hide: 0.63s . As you can see above, it is hard for the human eye to distinguish between the original and the merged image containing the text hidden inside. . Next, we will define a driver function to extract this hidden text from the image. . This simple function will accept the required inputs, call the extract function and save the extracted text in the file name that we provided. . def unhide(img, output, visualize, videofile): start_time = time.time() ret_val,unhidden_text = Steganography.unhide(img,visualize,videofile,debugMode) end_time = time.time() if not ret_val: print(&quot;!! Unhide Failure !!&quot;) return print(&quot;Total time taken for unhide: {:0.02f}s&quot;.format(end_time-start_time)) fp = open(output,&#39;wb&#39;) fp.write(unhidden_text) fp.close() . We will configure our input parameters as before, providing the input image and output text file along with some parameters to control if a visualization video is generated for the extraction process. . Feel free to set the true as false if you would prefer to skip the visualization. . img = &#39;../images/output.png&#39; output = &#39;../images/text_output.txt&#39; visualize = &#39;true&#39; videofile = &#39;visualize.mp4&#39; . All we need to do now is call the unhide function with our configuration parameters . unhide(img,output,visualize,videofile) . Begin processing image file . And voila!! . Our hidden text has magically appeared out of the image. . Lets see a visualization of the extraction process. . if visualize == &#39;true&#39; and os.path.exists(videofile): display(Video(data=videofile, width=1024)) . Hope you enjoyed this demo. . I encourage you to try running the above code with images and text of your choice and share you feedback. .",
            "url": "https://debalb.github.io/my-blogs/2020/06/28/steganography_text.html",
            "relUrl": "/2020/06/28/steganography_text.html",
            "date": " • Jun 28, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://debalb.github.io/my-blogs/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://debalb.github.io/my-blogs/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://debalb.github.io/my-blogs/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://debalb.github.io/my-blogs/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}